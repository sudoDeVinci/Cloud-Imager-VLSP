I've fallen down the rabbithole of ESP32 Arduino. I've continued imporoving the python code, which now includes a few more quality of life upates, such as better separation of responsibilities:
- Previously, all code to be loaded on a board would within a singular file. Functions were long and unweildy. This makes error handling more complex. Now functions are minimal, and responsibilities are distributed between lib files. AN example of this in main is get_encoded_readings() which calls get_bmp_sht_readings in the sensors lib:
    
    ```python
    
    def get_encoded_readings() -> bytes:
    from sensors import get_bmp_sht_readings
    sht_temp, sht_hum, bmp390_temp, bmp390_pressure, dewpoint = get_bmp_sht_readings()
    readings = "{0}|{1}|{2}|{3}|{4}".format(sht_temp, sht_hum, bmp390_temp, bmp390_pressure, dewpoint)
    return bytes(readings.encode('utf-8'))
    
    ```

    This separation and import means that when the sensors aren't being read, the entirety of the sensors lib doesn't need to be stored within memory. This also includes the i2c instances used to communicate with the sensors can be deleted and reinstantiated only when needed. Reduced memory and clock cycles in the context of the ESP32 also means reduced power consumption many times.


I haven't made any improvement to the C++ code since last time. I've been stuck understanding how the linker works. I also keep encountering very disheartening talk from people on forums about the complexity/lackluster implementation of networking on C++/Arduino.
Until I can find out for myself then, I continue my lessons about pointers and header files.

To avoid being burnt out by the singular task of learning, I go back and forth between that and the familiar python codebase to make more improvements.
I've also now completed the needed pieces for converting the received images to their undistorted form, to then be mapped onto a 3D space. This can be found in calibrator.py. I still need to go back to the lab to do this properly. I've also done some more manual garbage collection work on the graphing related scripts, dropping the memory usage closer now to 1-2GB peak. Moving away from a doing any File IO operations also caused a massive speedup.
For now, since I haven't been home, I've been remoting into my PC at home to work. This is mostly because, while it's a hassle, the speed is nowhere close. This speedup for running the scripts repeatedly during development is needed. However, today my internet at home has cut out for some reason, so I wont be able to use that PC. In addition to losing development speed, I'm now one version behind, so I'll be playing catch-up slightly.